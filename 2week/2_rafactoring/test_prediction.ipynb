{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainer import s2sTrainer\n",
    "from src.data import DeEndataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import sys\n",
    "from src.seq2seq import Encoder, Decoder, seq2seq\n",
    "\n",
    "train_data_paths = [\n",
    "        \"/home/jack/torchstudy/2week/1_refcode/.data/multi30k/train.de\",\n",
    "        \"/home/jack/torchstudy/2week/1_refcode/.data/multi30k/train.en\"\n",
    "    ]\n",
    "\n",
    "TrainDataset = DeEndataset(train_data_paths)\n",
    "\n",
    "encoder_config = {\n",
    "    \"emb_dim\" : 1000,\n",
    "    \"hid_dim\" : 1000,\n",
    "    \"lstm_layers\" : 4,\n",
    "    \"num_embeddings\" : len(TrainDataset.src_vocab),\n",
    "    \"pad_idx\" : TrainDataset.src_vocab.pad_idx\n",
    "}\n",
    "\n",
    "decoder_config = {\n",
    "    \"emb_dim\" : 1000,\n",
    "    \"hid_dim\" : 1000,\n",
    "    \"lstm_layers\" : 4,\n",
    "    \"num_embeddings\" : len(TrainDataset.dst_vocab),\n",
    "    \"pad_idx\" : TrainDataset.dst_vocab.pad_idx,\n",
    "    \"output_dim\" : len(TrainDataset.dst_vocab)\n",
    "}\n",
    "\n",
    "encoder = Encoder(**encoder_config)\n",
    "decoder = Decoder(**decoder_config)\n",
    "seq2seq = seq2seq(encoder, decoder)\n",
    "TrainDataset.src_vocab.build_index_dict()\n",
    "TrainDataset.dst_vocab.build_index_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Trainloader = DataLoader(TrainDataset, batch_size = 10, collate_fn=TrainDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tl in Trainloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
       "        [ 4, 15, 21, 21,  4, 21, 21, 21, 21, 70],\n",
       "        [ 5, 16, 25, 31, 16, 31, 31, 55, 63, 71],\n",
       "        [ 6, 17, 26, 17,  9, 17, 34, 26, 64, 36],\n",
       "        [ 7, 18, 27, 21, 40, 45, 52, 56, 21, 72],\n",
       "        [ 8, 19, 28, 32, 41, 46, 40, 36, 65, 17],\n",
       "        [ 9,  9, 21, 33, 42, 21, 21, 57, 66, 41],\n",
       "        [10, 20, 29, 34, 43, 47, 53, 58, 34, 73],\n",
       "        [11, 21, 30, 35, 44, 48, 54, 48, 67, 74],\n",
       "        [12, 22, 14, 36, 14, 41,  3, 59, 68, 41],\n",
       "        [13, 23,  3, 21,  3, 49,  0, 60, 21, 75],\n",
       "        [14, 24,  0, 37,  0, 31,  0, 61, 69, 14],\n",
       "        [ 3, 14,  0, 38,  0, 50,  0, 41, 14,  3],\n",
       "        [ 0,  3,  0, 21,  0, 51,  0, 62,  3,  0],\n",
       "        [ 0,  0,  0, 39,  0, 33,  0, 14,  0,  0],\n",
       "        [ 0,  0,  0, 14,  0, 14,  0,  3,  0,  0],\n",
       "        [ 0,  0,  0,  3,  0,  3,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, (b,c) = seq2seq.encoder.lstm(seq2seq.encoder.emb(tl[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.8653e-03, -4.2058e-03, -2.5996e-03,  ..., -1.2797e-02,\n",
       "           -4.5491e-03,  5.0520e-03],\n",
       "          [-3.9029e-03, -3.5952e-03, -5.5277e-03,  ..., -9.6980e-03,\n",
       "           -4.4721e-03,  8.3763e-03],\n",
       "          [-5.4942e-03, -5.6568e-03, -3.7973e-03,  ..., -1.2518e-02,\n",
       "           -4.3796e-03,  4.1578e-03],\n",
       "          ...,\n",
       "          [-1.3721e-03, -4.9914e-03, -2.5080e-04,  ..., -1.2988e-02,\n",
       "           -4.6839e-03,  5.9958e-03],\n",
       "          [-5.2516e-03, -6.1249e-03, -4.6869e-03,  ..., -1.1568e-02,\n",
       "           -3.6474e-03,  5.5232e-03],\n",
       "          [-3.7354e-03, -6.7820e-03, -1.8859e-03,  ..., -1.4510e-02,\n",
       "           -4.2517e-03,  5.3503e-03]],\n",
       " \n",
       "         [[-1.9114e-03, -7.3917e-04, -7.0411e-03,  ..., -1.5726e-02,\n",
       "           -8.6957e-03,  4.3373e-03],\n",
       "          [-3.0824e-03, -8.6521e-04, -8.3094e-03,  ..., -1.4446e-02,\n",
       "           -8.2494e-03,  6.8452e-03],\n",
       "          [-3.3405e-03, -1.9820e-03, -5.8452e-03,  ..., -1.6559e-02,\n",
       "           -9.1148e-03,  4.0979e-03],\n",
       "          ...,\n",
       "          [-3.1355e-04, -1.6099e-03, -4.2435e-03,  ..., -1.6473e-02,\n",
       "           -8.8068e-03,  5.7869e-03],\n",
       "          [-3.9862e-03, -2.2802e-03, -7.1488e-03,  ..., -1.5397e-02,\n",
       "           -7.8247e-03,  5.2099e-03],\n",
       "          [-2.7791e-03, -2.2868e-03, -5.6656e-03,  ..., -1.6511e-02,\n",
       "           -7.3698e-03,  5.0549e-03]],\n",
       " \n",
       "         [[-3.2252e-03,  1.4767e-03, -8.4952e-03,  ..., -1.6938e-02,\n",
       "           -1.1600e-02,  3.1137e-03],\n",
       "          [-3.3808e-03,  7.8530e-04, -9.0369e-03,  ..., -1.6848e-02,\n",
       "           -1.1608e-02,  5.5966e-03],\n",
       "          [-2.7492e-03,  4.9337e-04, -6.6128e-03,  ..., -1.7906e-02,\n",
       "           -1.2611e-02,  4.3499e-03],\n",
       "          ...,\n",
       "          [-5.2429e-05,  8.1379e-04, -5.7709e-03,  ..., -1.8074e-02,\n",
       "           -1.2429e-02,  5.9378e-03],\n",
       "          [-3.7993e-03,  1.0372e-03, -7.3604e-03,  ..., -1.6652e-02,\n",
       "           -1.1241e-02,  5.4335e-03],\n",
       "          [-3.4983e-03,  1.3140e-03, -7.8982e-03,  ..., -1.7691e-02,\n",
       "           -1.0335e-02,  5.4782e-03]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.1385e-02,  6.4225e-03, -1.2372e-02,  ..., -2.2239e-02,\n",
       "           -1.8496e-02,  5.6791e-03],\n",
       "          [-6.7649e-03,  5.5775e-03, -8.2037e-03,  ..., -2.2537e-02,\n",
       "           -1.8926e-02,  6.2169e-03],\n",
       "          [-9.0797e-03,  5.8390e-03, -1.0439e-02,  ..., -2.1789e-02,\n",
       "           -1.8399e-02,  4.9097e-03],\n",
       "          ...,\n",
       "          [-6.0244e-03,  5.3994e-03, -8.9886e-03,  ..., -2.0715e-02,\n",
       "           -1.2419e-02,  7.0896e-03],\n",
       "          [-5.9747e-03,  4.1418e-03, -7.4773e-03,  ..., -1.9099e-02,\n",
       "           -1.7302e-02,  8.1971e-03],\n",
       "          [-1.0897e-02,  4.6393e-03, -8.7884e-03,  ..., -2.2788e-02,\n",
       "           -1.8691e-02,  4.5722e-03]],\n",
       " \n",
       "         [[-1.1513e-02,  6.2006e-03, -1.2090e-02,  ..., -2.2183e-02,\n",
       "           -1.8075e-02,  5.3674e-03],\n",
       "          [-7.8255e-03,  5.7889e-03, -8.6586e-03,  ..., -2.2719e-02,\n",
       "           -1.8620e-02,  6.4805e-03],\n",
       "          [-8.9349e-03,  5.6889e-03, -1.0903e-02,  ..., -2.1126e-02,\n",
       "           -1.7860e-02,  4.3429e-03],\n",
       "          ...,\n",
       "          [-7.1923e-03,  5.3498e-03, -8.0093e-03,  ..., -2.1928e-02,\n",
       "           -1.3668e-02,  7.9879e-03],\n",
       "          [-7.0237e-03,  4.6143e-03, -8.2623e-03,  ..., -1.9609e-02,\n",
       "           -1.7375e-02,  7.9167e-03],\n",
       "          [-1.0761e-02,  4.8367e-03, -9.5072e-03,  ..., -2.2152e-02,\n",
       "           -1.8428e-02,  4.1635e-03]],\n",
       " \n",
       "         [[-1.1165e-02,  6.0037e-03, -1.1975e-02,  ..., -2.1730e-02,\n",
       "           -1.7559e-02,  4.8333e-03],\n",
       "          [-8.5113e-03,  5.8419e-03, -9.3714e-03,  ..., -2.2464e-02,\n",
       "           -1.8087e-02,  6.1800e-03],\n",
       "          [-8.6620e-03,  5.5975e-03, -1.1291e-02,  ..., -2.0489e-02,\n",
       "           -1.7401e-02,  3.8657e-03],\n",
       "          ...,\n",
       "          [-8.3307e-03,  5.3240e-03, -7.6665e-03,  ..., -2.2768e-02,\n",
       "           -1.4806e-02,  8.1777e-03],\n",
       "          [-7.6891e-03,  4.9827e-03, -9.1965e-03,  ..., -1.9765e-02,\n",
       "           -1.7221e-02,  7.1524e-03],\n",
       "          [-1.0336e-02,  5.0287e-03, -1.0226e-02,  ..., -2.1395e-02,\n",
       "           -1.7980e-02,  3.6958e-03]]], grad_fn=<StackBackward>),\n",
       " (tensor([[[ 0.0024,  0.0035, -0.0172,  ...,  0.0264,  0.0202, -0.0164],\n",
       "           [ 0.0010,  0.0185, -0.0446,  ...,  0.0191,  0.0201, -0.0038],\n",
       "           [ 0.0091, -0.0021, -0.0052,  ...,  0.0122, -0.0016, -0.0211],\n",
       "           ...,\n",
       "           [-0.0516,  0.0840, -0.0674,  ...,  0.0367,  0.1209, -0.0450],\n",
       "           [ 0.0076,  0.0307, -0.0485,  ...,  0.0153,  0.0263, -0.0290],\n",
       "           [ 0.0030,  0.0111, -0.0237,  ...,  0.0226, -0.0001, -0.0172]],\n",
       "  \n",
       "          [[-0.0013, -0.0238,  0.0249,  ..., -0.0005, -0.0023,  0.0027],\n",
       "           [-0.0056, -0.0290,  0.0027,  ..., -0.0084,  0.0026,  0.0043],\n",
       "           [-0.0108, -0.0237,  0.0305,  ...,  0.0019,  0.0078, -0.0078],\n",
       "           ...,\n",
       "           [-0.0129, -0.0373, -0.0329,  ..., -0.0100, -0.0247, -0.0056],\n",
       "           [-0.0116, -0.0273,  0.0055,  ...,  0.0051,  0.0041,  0.0103],\n",
       "           [-0.0013, -0.0343,  0.0159,  ..., -0.0024, -0.0041,  0.0023]],\n",
       "  \n",
       "          [[ 0.0196,  0.0141, -0.0059,  ...,  0.0211, -0.0275, -0.0129],\n",
       "           [ 0.0150,  0.0087, -0.0095,  ...,  0.0258, -0.0252, -0.0105],\n",
       "           [ 0.0204,  0.0115, -0.0050,  ...,  0.0231, -0.0247, -0.0152],\n",
       "           ...,\n",
       "           [ 0.0094,  0.0004, -0.0129,  ...,  0.0320, -0.0222, -0.0164],\n",
       "           [ 0.0181,  0.0082, -0.0078,  ...,  0.0326, -0.0214, -0.0132],\n",
       "           [ 0.0204,  0.0085, -0.0066,  ...,  0.0213, -0.0250, -0.0183]],\n",
       "  \n",
       "          [[-0.0112,  0.0060, -0.0120,  ..., -0.0217, -0.0176,  0.0048],\n",
       "           [-0.0085,  0.0058, -0.0094,  ..., -0.0225, -0.0181,  0.0062],\n",
       "           [-0.0087,  0.0056, -0.0113,  ..., -0.0205, -0.0174,  0.0039],\n",
       "           ...,\n",
       "           [-0.0083,  0.0053, -0.0077,  ..., -0.0228, -0.0148,  0.0082],\n",
       "           [-0.0077,  0.0050, -0.0092,  ..., -0.0198, -0.0172,  0.0072],\n",
       "           [-0.0103,  0.0050, -0.0102,  ..., -0.0214, -0.0180,  0.0037]]],\n",
       "         grad_fn=<StackBackward>),\n",
       "  tensor([[[ 0.0047,  0.0070, -0.0346,  ...,  0.0538,  0.0402, -0.0331],\n",
       "           [ 0.0019,  0.0376, -0.0912,  ...,  0.0388,  0.0397, -0.0078],\n",
       "           [ 0.0178, -0.0042, -0.0106,  ...,  0.0249, -0.0032, -0.0426],\n",
       "           ...,\n",
       "           [-0.0985,  0.1746, -0.1347,  ...,  0.0760,  0.2371, -0.0955],\n",
       "           [ 0.0148,  0.0622, -0.0982,  ...,  0.0312,  0.0527, -0.0583],\n",
       "           [ 0.0058,  0.0223, -0.0479,  ...,  0.0461, -0.0002, -0.0346]],\n",
       "  \n",
       "          [[-0.0027, -0.0477,  0.0501,  ..., -0.0011, -0.0046,  0.0052],\n",
       "           [-0.0113, -0.0571,  0.0055,  ..., -0.0168,  0.0053,  0.0084],\n",
       "           [-0.0218, -0.0474,  0.0611,  ...,  0.0038,  0.0157, -0.0156],\n",
       "           ...,\n",
       "           [-0.0257, -0.0741, -0.0695,  ..., -0.0202, -0.0516, -0.0109],\n",
       "           [-0.0234, -0.0545,  0.0111,  ...,  0.0102,  0.0083,  0.0203],\n",
       "           [-0.0026, -0.0686,  0.0320,  ..., -0.0047, -0.0081,  0.0045]],\n",
       "  \n",
       "          [[ 0.0394,  0.0291, -0.0114,  ...,  0.0420, -0.0550, -0.0252],\n",
       "           [ 0.0300,  0.0180, -0.0187,  ...,  0.0513, -0.0505, -0.0205],\n",
       "           [ 0.0411,  0.0238, -0.0098,  ...,  0.0459, -0.0494, -0.0300],\n",
       "           ...,\n",
       "           [ 0.0189,  0.0008, -0.0255,  ...,  0.0640, -0.0446, -0.0321],\n",
       "           [ 0.0366,  0.0170, -0.0153,  ...,  0.0649, -0.0428, -0.0260],\n",
       "           [ 0.0409,  0.0175, -0.0129,  ...,  0.0425, -0.0500, -0.0359]],\n",
       "  \n",
       "          [[-0.0228,  0.0121, -0.0247,  ..., -0.0429, -0.0352,  0.0098],\n",
       "           [-0.0174,  0.0118, -0.0194,  ..., -0.0444, -0.0362,  0.0126],\n",
       "           [-0.0177,  0.0113, -0.0233,  ..., -0.0406, -0.0349,  0.0079],\n",
       "           ...,\n",
       "           [-0.0171,  0.0107, -0.0158,  ..., -0.0449, -0.0295,  0.0167],\n",
       "           [-0.0157,  0.0100, -0.0190,  ..., -0.0391, -0.0344,  0.0145],\n",
       "           [-0.0211,  0.0101, -0.0211,  ..., -0.0422, -0.0360,  0.0075]]],\n",
       "         grad_fn=<StackBackward>)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.decoder.lstm(seq2seq.decoder.emb(tl[1]), (b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = seq2seq.encoder(tl[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 18])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl[0][0].T.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 18, 1000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0070, -0.0298,  0.0007,  ...,  0.0212, -0.0067, -0.0144],\n",
       "         [-0.0059, -0.0310,  0.0026,  ...,  0.0214, -0.0056, -0.0143],\n",
       "         [-0.0067, -0.0310,  0.0013,  ...,  0.0212, -0.0069, -0.0141],\n",
       "         ...,\n",
       "         [-0.0067, -0.0293,  0.0005,  ...,  0.0222, -0.0073, -0.0146],\n",
       "         [-0.0066, -0.0307,  0.0019,  ...,  0.0215, -0.0053, -0.0147],\n",
       "         [-0.0063, -0.0301,  0.0010,  ...,  0.0217, -0.0060, -0.0145]],\n",
       "\n",
       "        [[-0.0094, -0.0341,  0.0023,  ...,  0.0187, -0.0036, -0.0127],\n",
       "         [-0.0091, -0.0348,  0.0031,  ...,  0.0184, -0.0030, -0.0125],\n",
       "         [-0.0094, -0.0349,  0.0025,  ...,  0.0187, -0.0036, -0.0120],\n",
       "         ...,\n",
       "         [-0.0091, -0.0340,  0.0024,  ...,  0.0188, -0.0039, -0.0121],\n",
       "         [-0.0091, -0.0347,  0.0031,  ...,  0.0187, -0.0021, -0.0124],\n",
       "         [-0.0089, -0.0338,  0.0025,  ...,  0.0190, -0.0031, -0.0122]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0122, -0.0386,  0.0010,  ...,  0.0147,  0.0046, -0.0049],\n",
       "         [-0.0117, -0.0356,  0.0025,  ...,  0.0118,  0.0051, -0.0061],\n",
       "         [-0.0119, -0.0392,  0.0035,  ...,  0.0143,  0.0053, -0.0074],\n",
       "         ...,\n",
       "         [-0.0146, -0.0360,  0.0035,  ...,  0.0130,  0.0059, -0.0075],\n",
       "         [-0.0135, -0.0379,  0.0022,  ...,  0.0140,  0.0041, -0.0073],\n",
       "         [-0.0136, -0.0384,  0.0029,  ...,  0.0129,  0.0065, -0.0054]],\n",
       "\n",
       "        [[-0.0123, -0.0383,  0.0015,  ...,  0.0148,  0.0050, -0.0047],\n",
       "         [-0.0120, -0.0360,  0.0028,  ...,  0.0118,  0.0055, -0.0054],\n",
       "         [-0.0119, -0.0388,  0.0032,  ...,  0.0141,  0.0052, -0.0076],\n",
       "         ...,\n",
       "         [-0.0146, -0.0362,  0.0038,  ...,  0.0134,  0.0060, -0.0066],\n",
       "         [-0.0137, -0.0382,  0.0023,  ...,  0.0142,  0.0045, -0.0067],\n",
       "         [-0.0136, -0.0380,  0.0030,  ...,  0.0132,  0.0066, -0.0056]],\n",
       "\n",
       "        [[-0.0123, -0.0380,  0.0018,  ...,  0.0146,  0.0052, -0.0049],\n",
       "         [-0.0122, -0.0362,  0.0031,  ...,  0.0120,  0.0056, -0.0053],\n",
       "         [-0.0119, -0.0386,  0.0029,  ...,  0.0139,  0.0050, -0.0079],\n",
       "         ...,\n",
       "         [-0.0145, -0.0366,  0.0041,  ...,  0.0137,  0.0063, -0.0056],\n",
       "         [-0.0137, -0.0382,  0.0024,  ...,  0.0143,  0.0049, -0.0066],\n",
       "         [-0.0134, -0.0378,  0.0030,  ...,  0.0134,  0.0065, -0.0060]]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq(tl[0][0].T, tl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6670f6f92087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cuda/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability."
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "pack_padded_sequence(tl[0][0],tl[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((tensor([[ 3,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [21,  3,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [29, 21,  3,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [11, 29, 21,  3,  0,  0,  0,  0,  0,  0],\n",
      "        [46, 11, 60,  4,  3,  0,  0,  0,  0,  0],\n",
      "        [47, 30, 24,  5, 48,  0,  0,  0,  0,  0],\n",
      "        [48, 31, 61,  6, 69,  3,  3,  0,  0,  0],\n",
      "        [49, 32, 18,  7, 18, 21,  4,  3,  0,  0],\n",
      "        [50, 33, 62,  8, 35, 23,  7, 75,  3,  3],\n",
      "        [51, 34, 63,  9, 70, 24, 40, 76, 17, 21],\n",
      "        [12, 35, 51, 10, 71, 25, 41, 77,  7, 29],\n",
      "        [52, 36, 64, 11, 72, 11, 42, 11, 18, 55],\n",
      "        [29, 37, 65, 12, 59, 21, 37, 12, 19, 56],\n",
      "        [53, 38, 66, 13, 30, 26, 43, 78, 20, 57],\n",
      "        [32, 21, 67, 14, 73, 27, 44, 34, 21, 58],\n",
      "        [54, 39, 68, 15, 74, 28, 45, 79, 22, 59],\n",
      "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2]]), tensor([18, 17, 16, 15, 14, 12, 12, 11, 10, 10])), tensor([[ 0,  0,  0,  3,  0,  3,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0, 14,  0, 14,  0,  3,  0,  0],\n",
      "        [ 0,  0,  0, 39,  0, 33,  0, 14,  0,  0],\n",
      "        [ 0,  3,  0, 21,  0, 51,  0, 62,  3,  0],\n",
      "        [ 3, 14,  0, 38,  0, 50,  0, 41, 14,  3],\n",
      "        [14, 24,  0, 37,  0, 31,  0, 61, 69, 14],\n",
      "        [13, 23,  3, 21,  3, 49,  0, 60, 21, 75],\n",
      "        [12, 22, 14, 36, 14, 41,  3, 59, 68, 41],\n",
      "        [11, 21, 30, 35, 44, 48, 54, 48, 67, 74],\n",
      "        [10, 20, 29, 34, 43, 47, 53, 58, 34, 73],\n",
      "        [ 9,  9, 21, 33, 42, 21, 21, 57, 66, 41],\n",
      "        [ 8, 19, 28, 32, 41, 46, 40, 36, 65, 17],\n",
      "        [ 7, 18, 27, 21, 40, 45, 52, 56, 21, 72],\n",
      "        [ 6, 17, 26, 17,  9, 17, 34, 26, 64, 36],\n",
      "        [ 5, 16, 25, 31, 16, 31, 31, 55, 63, 71],\n",
      "        [ 4, 15, 21, 21,  4, 21, 21, 21, 21, 70],\n",
      "        [ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2]]))\n"
     ]
    }
   ],
   "source": [
    "print(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((tensor([[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [16, 16, 16, 16, 16, 16, 16, 16, 16, 16],\n",
      "        [54, 39, 68, 15, 74, 28, 45, 79, 22, 59],\n",
      "        [32, 21, 67, 14, 73, 27, 44, 34, 21, 58],\n",
      "        [53, 38, 66, 13, 30, 26, 43, 78, 20, 57],\n",
      "        [29, 37, 65, 12, 59, 21, 37, 12, 19, 56],\n",
      "        [52, 36, 64, 11, 72, 11, 42, 11, 18, 55],\n",
      "        [12, 35, 51, 10, 71, 25, 41, 77,  7, 29],\n",
      "        [51, 34, 63,  9, 70, 24, 40, 76, 17, 21],\n",
      "        [50, 33, 62,  8, 35, 23,  7, 75,  3,  3],\n",
      "        [49, 32, 18,  7, 18, 21,  4,  3,  0,  0],\n",
      "        [48, 31, 61,  6, 69,  3,  3,  0,  0,  0],\n",
      "        [47, 30, 24,  5, 48,  0,  0,  0,  0,  0],\n",
      "        [46, 11, 60,  4,  3,  0,  0,  0,  0,  0],\n",
      "        [11, 29, 21,  3,  0,  0,  0,  0,  0,  0],\n",
      "        [29, 21,  3,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [21,  3,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 3,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), tensor([18, 17, 16, 15, 14, 12, 12, 11, 10, 10])), tensor([[ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2],\n",
      "        [ 4, 15, 21, 21,  4, 21, 21, 21, 21, 70],\n",
      "        [ 5, 16, 25, 31, 16, 31, 31, 55, 63, 71],\n",
      "        [ 6, 17, 26, 17,  9, 17, 34, 26, 64, 36],\n",
      "        [ 7, 18, 27, 21, 40, 45, 52, 56, 21, 72],\n",
      "        [ 8, 19, 28, 32, 41, 46, 40, 36, 65, 17],\n",
      "        [ 9,  9, 21, 33, 42, 21, 21, 57, 66, 41],\n",
      "        [10, 20, 29, 34, 43, 47, 53, 58, 34, 73],\n",
      "        [11, 21, 30, 35, 44, 48, 54, 48, 67, 74],\n",
      "        [12, 22, 14, 36, 14, 41,  3, 59, 68, 41],\n",
      "        [13, 23,  3, 21,  3, 49,  0, 60, 21, 75],\n",
      "        [14, 24,  0, 37,  0, 31,  0, 61, 69, 14],\n",
      "        [ 3, 14,  0, 38,  0, 50,  0, 41, 14,  3],\n",
      "        [ 0,  3,  0, 21,  0, 51,  0, 62,  3,  0],\n",
      "        [ 0,  0,  0, 39,  0, 33,  0, 14,  0,  0],\n",
      "        [ 0,  0,  0, 14,  0, 14,  0,  3,  0,  0],\n",
      "        [ 0,  0,  0,  3,  0,  3,  0,  0,  0,  0]]))\n"
     ]
    }
   ],
   "source": [
    "print(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_hidden, enc_cell = seq2seq.encoder(tl[0][0], tl[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = seq2seq(tl[0][0], tl[0][1], tl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([170, 9795])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.view(-1, 9795).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  4, 15, 21, 21,  4, 21, 21, 21,\n",
       "        21, 70,  5, 16, 25, 31, 16, 31, 31, 55, 63, 71,  6, 17, 26, 17,  9, 17,\n",
       "        34, 26, 64, 36,  7, 18, 27, 21, 40, 45, 52, 56, 21, 72,  8, 19, 28, 32,\n",
       "        41, 46, 40, 36, 65, 17,  9,  9, 21, 33, 42, 21, 21, 57, 66, 41, 10, 20,\n",
       "        29, 34, 43, 47, 53, 58, 34, 73, 11, 21, 30, 35, 44, 48, 54, 48, 67, 74,\n",
       "        12, 22, 14, 36, 14, 41,  3, 59, 68, 41, 13, 23,  3, 21,  3, 49,  0, 60,\n",
       "        21, 75, 14, 24,  0, 37,  0, 31,  0, 61, 69, 14,  3, 14,  0, 38,  0, 50,\n",
       "         0, 41, 14,  3,  0,  3,  0, 21,  0, 51,  0, 62,  3,  0,  0,  0,  0, 39,\n",
       "         0, 33,  0, 14,  0,  0,  0,  0,  0, 14,  0, 14,  0,  3,  0,  0,  0,  0,\n",
       "         0,  3,  0,  3,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl[1].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 10, 9795])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0325e-01, 9.0797e-02, 7.4605e-02,  ..., 6.0461e-05, 8.0720e-02,\n",
       "        6.6195e-02], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.view(-1, 9795)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1088,  0.0678,  0.0490,  ...,  0.0028,  0.0644, -0.0093],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.view(-1, 9795)[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.2013, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(output.view(-1, 9795), tl[1].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\"\n",
    "test_sample = torch.Tensor([TrainDataset.src_vocab.stoi(src.lower(), option=\"seq2seq\", reverse=True)]).long().view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> /home/jack/torchstudy/2week/1_refcode/.data/multi30k/train.de <==\r\n",
      "Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\r\n",
      "Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\r\n",
      "\r\n",
      "==> /home/jack/torchstudy/2week/1_refcode/.data/multi30k/train.en <==\r\n",
      "Two young, White males are outside near many bushes.\r\n",
      "Several men in hard hats are operating a giant pulley system.\r\n"
     ]
    }
   ],
   "source": [
    "!head -2 /home/jack/torchstudy/2week/1_refcode/.data/multi30k/train.de /home/jack/torchstudy/2week/1_refcode/.data/multi30k/train.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\"\n",
    "test_sample = torch.Tensor([TrainDataset.src_vocab.stoi(src.lower(), option=\"seq2seq\", reverse=True)]).long().view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS>\n",
      ".\n",
      "antriebsradsystem\n",
      "ein\n",
      "bedienen\n",
      "schutzhelmen\n",
      "mit\n",
      "männer\n",
      "mehrere\n",
      "<EOS>\n"
     ]
    }
   ],
   "source": [
    "for i in test_sample:\n",
    "    print(TrainDataset.src_vocab.index_dict[int(i[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq2seq.load_state_dict(torch.load(\"./seq2seq-model.pt\"))\n",
    "outs, probs = [], []\n",
    "break_point = 20\n",
    "trial = 1\n",
    "now_token = torch.Tensor([2]).to(torch.int64)\n",
    "with torch.no_grad():\n",
    "    emb = seq2seq.encoder.emb(test_sample)\n",
    "    out, (hidden, cell) = seq2seq.encoder.lstm(emb) \n",
    "    while True:\n",
    "        output, hidden, cell = seq2seq.decoder(now_token, hidden, cell)\n",
    "        next_index = int(output.argmax())\n",
    "        if next_index == 3:\n",
    "            break\n",
    "\n",
    "        outs.append(next_index)\n",
    "        now_token = torch.Tensor([next_index]).long()\n",
    "#         probs.append(float(torch.nn.Softmax(dim=2)(output).max()))\n",
    "\n",
    "        trial += 1\n",
    "        if trial == break_point:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a man in a blue shirt is standing in front of a building .'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([TrainDataset.dst_vocab.index_dict[index] for index in outs if TrainDataset.dst_vocab.index_dict[index] != \"<PAD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_token = torch.Tensor([[next_index]]).to(torch.int64)\n",
    "output, hidden, cell = seq2seq.decoder(now_token, hid, cell)\n",
    "next_index = int(output.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4576"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, pred_probs = seq2seq.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, hidden, cell = seq2seq.decoder(now_token, hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 1000])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (4, 1, 1000), got [4, 11, 1000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-6bf9a12f016e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print(pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchstudy/2week/2_rafactoring/src/seq2seq.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs, sos_token, eos_idx)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m                 \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnext_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0meos_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cuda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchstudy/2week/2_rafactoring/src/seq2seq.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_hidden_state, encoder_cell_state)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# encoder_hidden_state(input) : [num_layer * num_direction, batch, hidden_size ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_cell_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;31m# out : [ sequence_len, batch_size, num_direction * hidden_size ]. (batch_first = False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# hidden : [ num_layer * num_direction, batch, hidden_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cuda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cuda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[0;32m~/anaconda3/envs/cuda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         self.check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[0;32m--> 534\u001b[0;31m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[1;32m    535\u001b[0m         self.check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[1;32m    536\u001b[0m                                'Expected hidden[1] size {}, got {}')\n",
      "\u001b[0;32m~/anaconda3/envs/cuda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    194\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden[0] size (4, 1, 1000), got [4, 11, 1000]"
     ]
    }
   ],
   "source": [
    "src = \"Jungen tanzen mitten in der Nacht auf Pfosten.\"\n",
    "test_sample = torch.Tensor([[TrainDataset.src_vocab.stoi(src.lower(), option=\"seq2seq\", reverse=True)]]).long()\n",
    "\n",
    "seq2seq.load_state_dict(torch.load(\"./seq2seq-model.pt\"))\n",
    "\n",
    "test_sample = torch.reshape(test_sample, (-1,1))\n",
    "pred, pred_probs = seq2seq.predict(test_sample)\n",
    "\n",
    "# print(pred)\n",
    "# print(TrainDataset.dst_vocab.itos(pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden, cell = seq2seq.encoder.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 1000])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 1000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1000])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_token_emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4758"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_token = torch.Tensor([[4758]]).to(torch.int64)\n",
    "now_token_emb = seq2seq.decoder.emb(now_token)\n",
    "output, (hidden, cell) = seq2seq.decoder.lstm(now_token_emb, (hidden, cell))\n",
    "output = seq2seq.decoder.fc_out(output)\n",
    "int(output.argmax())\n",
    "# next_index = int(output.argmax())\n",
    "# if next_index == eos_idx:\n",
    "#     break\n",
    "\n",
    "# outs.append(next_index)\n",
    "# now_token = torch.Tensor([next_index]).to(torch.int64)\n",
    "# probs.append(float(torch.nn.Softmax(dim=2)(output).max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1000])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -9.2795,  -8.9954,  -7.7406,  ..., -10.4585,  -8.8203,  -5.4389]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-20-320ba166d17a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-320ba166d17a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    seq2seq.encoder(test_sample, torch.Tensor([len(test_sample)])\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    def predict(self, inputs, input_len, sos_token=2, eos_idx=3):\n",
    "        hidden, cell = self.encoder(inputs, torch.tensor([input_len]).long())\n",
    "\n",
    "        outs = []\n",
    "        probs = []\n",
    "\n",
    "        now_token = torch.Tensor([sos_token]).to(torch.int64)\n",
    "        trial = 0\n",
    "        break_point = 100\n",
    "        with torch.no_grad():\n",
    "            while True:\n",
    "                output, hidden, cell = self.decoder(now_token, hidden, cell)\n",
    "                next_index = int(output.argmax())\n",
    "                if next_index == eos_idx:\n",
    "                    break\n",
    "\n",
    "                outs.append(next_index)\n",
    "                now_token = torch.Tensor([next_index]).to(torch.int64)\n",
    "                probs.append(float(torch.nn.Softmax(dim=2)(output).max()))\n",
    "\n",
    "                trial += 1\n",
    "                if trial == break_point:\n",
    "                    break\n",
    "        return outs, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SOS>',\n",
       " '.',\n",
       " 'pfosten',\n",
       " 'auf',\n",
       " 'nacht',\n",
       " 'der',\n",
       " 'in',\n",
       " 'mitten',\n",
       " 'tanzen',\n",
       " 'jungen',\n",
       " '<EOS>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = list(test_sample.numpy().flatten())\n",
    "[TrainDataset.src_vocab.index_dict[index] for index in indices if TrainDataset.src_vocab.index_dict[index] != \"<PAD>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workers',\n",
       " 'members',\n",
       " 'i',\n",
       " 'to',\n",
       " 'to',\n",
       " '\"',\n",
       " '\"',\n",
       " '\"',\n",
       " '\"',\n",
       " '\"',\n",
       " '\"',\n",
       " '\"',\n",
       " '\"',\n",
       " '\"',\n",
       " '\"',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[TrainDataset.dst_vocab.index_dict[index] for index in outs if TrainDataset.dst_vocab.index_dict[index] != \"<PAD>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21, 31, 17, 21, 90, 33, 34, 35, 17, 111, 74, 21, 65, 489, 14]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itos(self, indices):\n",
    "    if type(indices) == int:\n",
    "        return \" \".join([self.index_dict[index] for index in indices if self.index_dict[index] != \"<PAD>\"])\n",
    "    elif type(indices[0]) == list:\n",
    "        return [self.itos(i) for i in indices]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
