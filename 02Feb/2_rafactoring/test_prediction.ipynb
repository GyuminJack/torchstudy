{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainer import s2sTrainer\n",
    "from src.data import DeEndataset, KoEndataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import sys\n",
    "from src.seq2seq import Encoder, Decoder, seq2seq\n",
    "\n",
    "train_data_paths = [\n",
    "    \"/home/jack/torchstudy/02Feb/0_datas/korean-english-park.train.ko\",\n",
    "    \"/home/jack/torchstudy/02Feb/0_datas/korean-english-park.train.en\"\n",
    "]\n",
    "\n",
    "\n",
    "TrainDataset = KoEndataset(train_data_paths)\n",
    "\n",
    "encoder_config = {\n",
    "    \"emb_dim\" : 1000,\n",
    "    \"hid_dim\" : 1000,\n",
    "    \"n_layers\" : 4,\n",
    "    \"input_dim\" : len(TrainDataset.src_vocab),\n",
    "    \"pad_idx\" : TrainDataset.src_vocab.pad_idx\n",
    "}\n",
    "\n",
    "decoder_config = {\n",
    "    \"emb_dim\" : 1000,\n",
    "    \"hid_dim\" : 1000,\n",
    "    \"n_layers\" : 4,\n",
    "    \"pad_idx\" : TrainDataset.dst_vocab.pad_idx,\n",
    "    \"output_dim\" : len(TrainDataset.dst_vocab)\n",
    "}\n",
    "\n",
    "encoder = Encoder(**encoder_config)\n",
    "decoder = Decoder(**decoder_config)\n",
    "seq2seq = seq2seq(encoder, decoder)\n",
    "TrainDataset.src_vocab.set_most_common_dict(6000)\n",
    "TrainDataset.dst_vocab.set_most_common_dict(6000)\n",
    "TrainDataset.src_vocab.build_index_dict()\n",
    "TrainDataset.dst_vocab.build_index_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seq2seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(6004, 1000)\n",
       "    (rnn): LSTM(1000, 1000, num_layers=4, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (emb): Embedding(6004, 1000, padding_idx=0)\n",
       "    (rnn): LSTM(1000, 1000, num_layers=4, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=1000, out_features=6004, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, token, max_length=50):\n",
    "   \n",
    "    text_to_indices = token\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices)\n",
    "    model.eval()\n",
    "    # Build encoder hidden, cell state\n",
    "    with torch.no_grad():\n",
    "        embedded = model.encoder.dropout(model.encoder.embedding(sentence_tensor))\n",
    "        _, (hidden, cell) = model.encoder.rnn(embedded)\n",
    "\n",
    "        outputs = [2]\n",
    "\n",
    "        for _ in range(max_length):\n",
    "            previous_word = torch.LongTensor([outputs[-1]])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
    "                best_guess = output.argmax(1).item()\n",
    "\n",
    "            outputs.append(best_guess)\n",
    "\n",
    "            # Model predicts it's the end of the sentence\n",
    "            if output.argmax(1).item() == 3:\n",
    "                break\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq.load_state_dict(torch.load(\"seq2seq-model-ko-en.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jack/torchstudy/02Feb/0_datas/korean-english-park.dev.en'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/home/jack/torchstudy/02Feb/0_datas/korean-english-park.dev.ko\"\n",
    "\"/home/jack/torchstudy/02Feb/0_datas/korean-english-park.dev.en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"사우디 한국 미국\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = torch.Tensor([TrainDataset.src_vocab.stoi(src.lower(), option=\"seq2seq\", reverse=True)]).long().view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS> the government has said it will <UNK> the <UNK> of the korean government . <EOS>'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([TrainDataset.dst_vocab.index_dict[i] for i in translate_sentence(seq2seq, test_sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference: [['1', '2', '3', '4']]\n",
      "candidate: ['1', '2', '3']\n",
      "BLEU: 0.7165313105737893\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['1', '2', '3', '4']]\n",
    "candidate = ['1', '2', '3']\n",
    "bleu = sentence_bleu(reference, candidate, weights=(0.3,0.3,0.3))\n",
    "\n",
    "print(f'reference: {reference}')\n",
    "print(f'candidate: {candidate}')\n",
    "print('BLEU:', bleu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7165313105737893\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "candidate_corpus = [['1', '3', '4', '5'], ['Another', 'Sentence']]\n",
    "references_corpus = [[['2', '3', '4', '5'], ['Completely', 'Different']], [['No', 'Match']]]\n",
    "bleu = sentence_bleu(reference, candidate, weights=(0.3,0.3,0.3))\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
